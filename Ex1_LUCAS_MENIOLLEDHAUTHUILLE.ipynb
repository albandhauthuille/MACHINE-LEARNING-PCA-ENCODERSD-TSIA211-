{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iafPdtuncbq7"
   },
   "source": [
    "<h1><center>MNIST classification using Numpy<center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I4VrCB5La5rD"
   },
   "source": [
    "## Importing Numpy and Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OlKZ3Hnas7B4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tensorflow version 1.10.0\n",
      "Using keras version 2.2.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "print(\"Using tensorflow version \" + str(tf.__version__))\n",
    "print(\"Using keras version \" + str(keras.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s_QLz9_jbRZq"
   },
   "source": [
    "## Loading and preparing the MNIST dataset\n",
    "Load the MNIST dataset made available by keras.datasets. Check the size of the training and testing sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "gG83hGyVmijn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "    taille de x_train: (60000, 28, 28)\n",
      "    taille de y_train: (60000,)\n",
      "\n",
      "Testing set:\n",
      "    taille de x_test: (10000, 28, 28)\n",
      "    taille de y_test: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# The MNSIT dataset is ready to be imported from Keras into RAM\n",
    "# Warning: you cannot do that for larger databases (e.g., ImageNet)\n",
    "from keras.datasets import mnist\n",
    "(x_train, y_train),(x_test, y_test) =mnist.load_data(path=\"mnist.npz\")\n",
    "\n",
    "\n",
    "\n",
    "# START CODE HERE\n",
    "print(\"Training set:\")\n",
    "print(\"    taille de x_train:\",np.shape(x_train))\n",
    "print(\"    taille de y_train:\",np.shape(y_train))\n",
    "print('\\nTesting set:')\n",
    "print(\"    taille de x_test:\",np.shape(x_test))\n",
    "print(\"    taille de y_test:\",np.shape(y_test))\n",
    "# END CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gRPbU_Z4U6Ac"
   },
   "source": [
    "The MNIST database contains 60,000 training images and 10,000 testing images.\n",
    "Using the pyplot package, visualize the first sample of the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x5VAu7oW0Zu4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let us visualize the first training sample using the Matplotlib library\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# START CODE HERE\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15,8))\n",
    "for i in range(9):\n",
    "    ax = axes[i//3, i%3]\n",
    "    ax.imshow(x_train[i], cmap='gray')\n",
    "    ax.set_title(\"image nÂ°\"+str(i+1))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s7YsRekMVDg-"
   },
   "source": [
    "The database contains images of handwritten digits. Hence, they belong to one of 10 categories, depending on the digit they represent. \n",
    "Reminder: in order to do multi-class classification, we use the softmax function, which outputs a multinomial probability distribution. That means that the output to our model will be a vector of size $10$, containing probabilities (meaning that the elements of the vector will be positive sum to $1$).\n",
    "For easy computation, we want to true labels to be represented with the same format: that is what we call **one-hot encoding**. For example, if an image $\\mathbf{x}$ represents the digit $5$, we have the corresponding one_hot label (careful, $0$ will be the first digit): \n",
    "$$ \\mathbf{y} = [0, 0, 0, 0, 0, 1, 0, 0, 0, 0] $$\n",
    "Here, you need to turn train and test labels to one-hot encoding using the following function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "y_train_simple = np.copy(y_train)\n",
    "y_test_simple = np.copy(y_test)\n",
    "\n",
    "# START CODE HERE\n",
    "boolean = True\n",
    "if boolean:\n",
    "    y_train, y_test = to_categorical(y_train),to_categorical(y_test)\n",
    "    boolean = False\n",
    "y_train\n",
    "# END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0jv29YLtVO3q"
   },
   "source": [
    "Images are black and white, with size $28 \\times 28$. We will work with them using a simple linear classification model, meaning that we will have them as vectors of size $(784)$.\n",
    "You should then transform the images to the size $(784)$ using the numpy function ```reshape```.\n",
    "\n",
    "Then, after casting the pixels to floats, normalize the images so that they have zero-mean and unitary deviation. Be careful to your methodology: while you have access to training data, you may not have access to testing data, and must avoid using any statistic on the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ptTRSDo5nJyZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new shape of the image is:  (60000, 784)\n",
      "The new shape of the image is:  (10000, 784)\n",
      "\n",
      "New mean of the train_image:  -1.7174248e-09\n",
      "New std of the train_image:  0.95633847\n",
      "\n",
      "New mean of the test_image:  0.0024957662\n",
      "New std of the test_image:  0.9571717\n"
     ]
    }
   ],
   "source": [
    "# Reshape to proper images with 1 color channel according to backend scheme\n",
    "img_rows, img_cols = x_train.shape[1], x_train.shape[2]\n",
    "\n",
    "# START CODE HERE\n",
    "train_images = x_train.reshape(60000,-1)\n",
    "test_images = x_test.reshape(10000,-1)\n",
    "print(\"The new shape of the image is: \",np.shape(train_images))\n",
    "print(\"The new shape of the image is: \",np.shape(test_images))\n",
    "\n",
    "# END CODE HERE\n",
    "\n",
    "# Cast pixels from uint8 to float32\n",
    "train_images = train_images.astype('float32')\n",
    "test_images = test_images.astype('float32')\n",
    "\n",
    "# Now let us normalize the images so that they have zero mean and standard deviation\n",
    "# Hint: are real testing data statistics known at training time ?\n",
    "# START CODE HERE\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train_images = scaler.fit_transform(train_images)\n",
    "test_images = scaler.transform(test_images)\n",
    "\n",
    "print(\"\\nNew mean of the train_image: \",np.mean(train_images))\n",
    "print(\"New std of the train_image: \",np.std(train_images))\n",
    "\n",
    "print(\"\\nNew mean of the test_image: \",np.mean(test_images))\n",
    "print(\"New std of the test_image: \",np.std(test_images))\n",
    "# END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Numpy\n",
    "\n",
    "Look at this [cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf) for some basic information on how to use numpy.\n",
    "\n",
    "## Defining the model \n",
    "\n",
    "We will here create a simple, linear classification model. We will take each pixel in the image as an input feature (making the size of the input to be $784$) and transform these features with a weight matrix $\\mathbf{W}$ and a bias vector $\\mathbf{b}$. Since there is $10$ possible classes, we want to obtain $10$ scores. Then, \n",
    "$$ \\mathbf{W} \\in \\mathbb{R}^{784 \\times 10} $$\n",
    "$$ \\mathbf{b} \\in \\mathbb{R}^{10} $$\n",
    "\n",
    "and our scores are obtained with:\n",
    "$$ \\mathbf{z} = \\mathbf{W}^{T} \\mathbf{x} +  \\mathbf{b} $$\n",
    "\n",
    "where $\\mathbf{x} \\in \\mathbb{R}^{784}$ is the input vector representing an image.\n",
    "We note $\\mathbf{y} \\in \\mathbb{R}^{10}$ as the target one_hot vector. \n",
    "\n",
    "Here, you fist need to initialize $\\mathbf{W}$ and $\\mathbf{b}$ using ```np.random.normal``` and ```np.zeros```, then compute $\\mathbf{z}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid implementing a complicated gradient back-propagation,\n",
    "# we will try a very simple architecture with one layer \n",
    "def initLayer(n_input,n_output):\n",
    "    \"\"\"\n",
    "    Initialize the weights, return the number of parameters\n",
    "    Inputs: n_input: the number of input units - int\n",
    "          : n_output: the number of output units - int\n",
    "    Outputs: W: a matrix of weights for the layer - numpy ndarray\n",
    "           : b: a vector bias for the layer - numpy ndarray\n",
    "           : nb_params: the number of parameters  - int\n",
    "    \"\"\"\n",
    "    # START CODE HERE\n",
    "    W = np.random.normal(size = (n_input,n_output))\n",
    "    b = np.zeros(n_output)\n",
    "    nb_params = np.shape(W)[0]*np.shape(W)[1]+np.shape(b)[0]\n",
    "    # END CODE HERE\n",
    "    return W, b, nb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_training = train_images.shape[0] \n",
    "n_feature = len(train_images[0])\n",
    "n_labels = 10\n",
    "W, b, nb_params = initLayer(n_feature, n_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(W, b, X):\n",
    "    \"\"\"\n",
    "    Perform the forward propagation\n",
    "    Inputs: W: the weights - numpy ndarray\n",
    "          : b: the bias - numpy ndarray\n",
    "          : X: the batch - numpy ndarray\n",
    "    Outputs: z: outputs - numpy ndarray\n",
    "    \"\"\"\n",
    "    z = X@W + b\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the output \n",
    "\n",
    "To obtain classification probabilities, we use the softmax function:\n",
    "$$ \\mathbf{o} = softmax(\\mathbf{z}) \\text{         with          } o_i = \\frac{\\exp(z_i)}{\\sum_{j=0}^{9} \\exp(z_j)} $$\n",
    "\n",
    "The usual difficulty with the softmax function is the possibility of overflow when the scores $z_i$ are already large. Since a softmax is not affected by a shift affecting the whole vector $\\mathbf{z}$:\n",
    "$$ \\frac{\\exp(z_i - c)}{\\sum_{j=0}^{9} \\exp(z_j - c)} =  \\frac{\\exp(c) \\exp(z_i)}{\\exp(c) \\sum_{j=0}^{9} \\exp(z_j)} = \\frac{\\exp(z_i)}{\\sum_{j=0}^{9} \\exp(z_j)}$$\n",
    "what trick can we use to ensure we will not encounter any overflow ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    \"\"\"\n",
    "    Perform the softmax transformation to the pre-activation values\n",
    "    Inputs: z: the pre-activation values - numpy ndarray\n",
    "    Outputs: out: the activation values - numpy ndarray\n",
    "    \"\"\"\n",
    "    # We can use the following trick: using z-max(zi) instead of simpply z. The output will be unchanged.\n",
    "    a = np.exp(z-np.max(z))\n",
    "    out = a/np.sum(a)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making updates\n",
    "\n",
    "We define a learning rate $\\eta$. The goal is to be able to apply updates:\n",
    "$$ \\mathbf{W}^{t+1} = \\mathbf{W}^{t} + \\nabla_{\\mathbf{W}} l_{MLE} $$\n",
    "\n",
    "In order to do this, we will compute this gradient (and the bias) in the function ```update```. In the next function ```updateParams```, we will actually apply the update with regularization. \n",
    "\n",
    "Reminder: the gradient $\\nabla_{\\mathbf{W}} l_{MLE}$ is the matrix containing the partial derivatives \n",
    "$$ \\left[\\frac{\\delta l_{MLE}}{\\delta W_{ij}}\\right]_{i=1..784, j=1..10} $$\n",
    "**Remark**: Careful, the usual way of implementing this in python has the dimensions of $\\mathbf{W}$ reversed compared to the notation of the slides.\n",
    "\n",
    "Coordinate by coordinate, we obtain the following update: \n",
    "$$ W_{ij}^{t+1} = W_{ij}^{t} + \\eta \\frac{\\delta l_{MLE}}{\\delta W_{ij}} $$\n",
    "\n",
    "Via the chain rule, we obtain, for an input feature $i \\in [0, 783]$ and a output class $j \\in [0, 9]$: $$\\frac{\\delta l_{MLE}}{\\delta W_{ij}} = \\frac{\\delta l_{MLE}}{\\delta z_{j}} \\frac{\\delta z_j}{\\delta W_{ij}}$$ \n",
    "\n",
    "It's easy to compute that $\\frac{\\delta z_j}{\\delta W_{ij}} = x_i$\n",
    "\n",
    "We compute the softmax derivative, to obtain:\n",
    "$$ \\nabla_{\\mathbf{z}} l_{MLE} = \\mathbf{o} - \\mathbf{y} $$\n",
    "\n",
    "Hence, $\\frac{\\delta l_{MLE}}{\\delta z_{j}} = o_j - y_j$ and we obtain that $$\\frac{\\delta l_{MLE}}{\\delta W_{ij}} = (o_j - y_j) x_i$$\n",
    "\n",
    "This can easily be written as a scalar product, and a similar computation (even easier, actually) can be done for $\\mathbf{b}$. Noting $\\nabla_{\\mathbf{z}} l_{MLE} = \\mathbf{o} - \\mathbf{y}$ as ```grad``` in the following function, compute the gradients $\\nabla_{\\mathbf{W}} l_{MLE}$ and $\\nabla_{\\mathbf{b}} l_{MLE}$ in order to call the function ```updateParams```.\n",
    "\n",
    "Note: the regularizer and the weight_decay $\\lambda$ are used in ```updateParams```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(eta, W, b, grad, X, regularizer, weight_decay):\n",
    "    \"\"\"\n",
    "    Perform the update of the parameters\n",
    "    Inputs: eta: the step-size of the gradient descent - float \n",
    "          : W: the weights - ndarray\n",
    "          : b: the bias -  ndarray\n",
    "          : grad: the gradient of the activations w.r.t. to the loss -  list of ndarray\n",
    "          : X: the data -  ndarray\n",
    "          : regularizer: 'L2' or None - the regularizer to be used in updateParams\n",
    "          : weight_decay: the weight decay to be used in updateParams - float\n",
    "    Outputs: W: the weights updated -  ndarray\n",
    "           : b: the bias updated -  ndarray\n",
    "    \"\"\"\n",
    "    grad_w = X.reshape((-1,1)) @ grad.reshape((-1,1)).T\n",
    "    grad_b = grad\n",
    "        \n",
    "    W = updateParams(W, grad_w, eta, regularizer, weight_decay)\n",
    "    b = updateParams(b, grad_b, eta, regularizer, weight_decay)\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The update rule is affected by regularization. We implement two cases: No regularization, or L2 regularization. Use the two possible update rules to implement the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateParams(param, grad_param, eta, regularizer=None, weight_decay=0.):\n",
    "    \"\"\"\n",
    "    Perform the update of the parameters\n",
    "    Inputs: param: the network parameters - ndarray\n",
    "          : grad_param: the updates of the parameters - ndarray\n",
    "          : eta: the step-size of the gradient descent - float\n",
    "          : weight_decay: the weight-decay - float\n",
    "    Outputs: the parameters updated - ndarray\n",
    "    \"\"\"\n",
    "    if regularizer==None:\n",
    "        return param-eta*grad_param\n",
    "    elif regularizer=='L2':\n",
    "        return (1 - 2*weight_decay)*param - eta*grad_param\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the Accuracy\n",
    "\n",
    "Here, we simply use the model to predict the class (by taking the argmax of the output !) for every example in ```X```, and count the number of times the model is right, to output the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAcc(W, b, X, labels):\n",
    "    \"\"\"\n",
    "    Compute the loss value of the current network on the full batch\n",
    "    Inputs: act_func: the activation function - function\n",
    "          : W: the weights - list of ndarray\n",
    "          : B: the bias - list of ndarray\n",
    "          : X: the batch - ndarray\n",
    "          : labels: the labels corresponding to the batch\n",
    "    Outputs: loss: the negative log-likelihood - float\n",
    "           : accuracy: the ratio of examples that are well-classified - float\n",
    "    \"\"\" \n",
    "    ### Forward propagation\n",
    "    z = forward(W,b,X)\n",
    "    \n",
    "    ### Compute the softmax and the prediction\n",
    "    out = softmax(z)\n",
    "    \n",
    "    pred = np.argmax(z,axis=1)\n",
    "    labels = np.argmax(labels,axis=1)\n",
    "    \n",
    "    ###Â Compute the accuracy\n",
    "    accuracy = np.mean([pred==labels])\n",
    "      \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing training\n",
    "\n",
    "The following hyperparameters are given. Next, we can assemble all the function previously defined to implement a training loop. We will train the classifier on **one epoch**, meaning that the model will see each trainin example once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization\n",
    "eta = 0.01\n",
    "regularizer = 'L2'\n",
    "weight_decay = 0.0001\n",
    "\n",
    "# Training\n",
    "log_interval = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      On train: 0.07193333333333334    On test:0.0651    Eta:0.01\n",
      "5000      On train: 0.8230833333333333    On test:0.8239    Eta:0.01\n",
      "10000      On train: 0.8584    On test:0.8594    Eta:0.01\n",
      "15000      On train: 0.8431166666666666    On test:0.8412    Eta:0.01\n",
      "20000      On train: 0.8399    On test:0.8477    Eta:0.01\n",
      "25000      On train: 0.8484    On test:0.8532    Eta:0.01\n",
      "30000      On train: 0.8509    On test:0.8528    Eta:0.01\n",
      "35000      On train: 0.83895    On test:0.841    Eta:0.01\n",
      "40000      On train: 0.852    On test:0.8521    Eta:0.01\n",
      "45000      On train: 0.8551    On test:0.8555    Eta:0.01\n",
      "50000      On train: 0.8495833333333334    On test:0.8552    Eta:0.01\n",
      "55000      On train: 0.8299833333333333    On test:0.8329    Eta:0.01\n",
      "Final result:    On train:0.8299833333333333    On test:0.8329    Eta:0.01\n"
     ]
    }
   ],
   "source": [
    "# Data structures for plotting\n",
    "g_train_acc=[]\n",
    "g_valid_acc=[]\n",
    "\n",
    "W,b,nb = initLayer(784,10)\n",
    "\n",
    "#######################\n",
    "### Learning process ##\n",
    "#######################\n",
    "n_training = len(train_images)\n",
    "for j in range(n_training):\n",
    "    ### Getting the example\n",
    "    X, y = train_images[j],y_train[j]\n",
    "\n",
    "    ### Forward propagation\n",
    "    z = forward(W,b,X)\n",
    "\n",
    "    ### Compute the softmax\n",
    "    out = softmax(z)\n",
    "        \n",
    "    ### Compute the gradient at the top layer\n",
    "    derror = out - y # This is o - y \n",
    "\n",
    "    ### Update the parameters\n",
    "    Wcopy = np.copy(W)\n",
    "    W, b = update(eta, Wcopy, b, derror, X, regularizer, weight_decay)\n",
    "\n",
    "\n",
    "    if j % log_interval == 0:\n",
    "        ### Every log_interval examples, look at the training accuracy\n",
    "        train_accuracy = computeAcc(W, b, train_images, y_train) \n",
    "\n",
    "        ### And the testing accuracy\n",
    "        test_accuracy = computeAcc(W, b, test_images, y_test) \n",
    "\n",
    "        g_train_acc.append(train_accuracy)\n",
    "        g_valid_acc.append(test_accuracy)\n",
    "        result_line = str(int(j)) + \"      On train: \" + str(train_accuracy) + \"    On test:\" + str(test_accuracy) + \"    Eta:\" + str(eta)\n",
    "        print(result_line)\n",
    "\n",
    "g_train_acc.append(train_accuracy)\n",
    "g_valid_acc.append(test_accuracy)\n",
    "result_line = \"Final result:\" + \"    On train:\" + str(train_accuracy) + \"    On test:\" + str(test_accuracy) + \"    Eta:\" + str(eta)\n",
    "print(result_line)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "plt.title('Accuracy on both sets')\n",
    "plt.grid()\n",
    "plt.plot(g_train_acc,label='training set')\n",
    "plt.plot(g_valid_acc,label='testing set')\n",
    "plt.legend()\n",
    "plt.xlabel('number of iterations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What can you say about the performance of this simple linear classifier ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Performance is very very good wit this simple linear classifier as the latter results show it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TP4_1_empty.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
